{% extends "base.html" %} {% block content %}

<script>

    var cifar10_info = JSON.parse('{{ cifar10_info | default("") | tojson | safe}}');
    var show_modal = JSON.parse('{{ show_modal | default("") | tojson | safe }}');
    var username = JSON.parse('{{ username | default("") | tojson | safe }}');
    var additional_info = JSON.parse('{{ additional_info | default("") | tojson | safe }}');
    var accuracy = 0.0;
    if (username!=""){username=username.username;}

    
    $(document).ready(function () {
        if (additional_info!=""){
            var accuracy = additional_info.accuracy;
            $(".put-result").text("Score: " + accuracy.toString())
        }
        db_info(cifar10_info, $(".table-cifar10"), username);
        if(show_modal!="" && !jQuery.isEmptyObject(show_modal)){manage_modals(show_modal);}
        if(username!=""){
            $(".submit-btn").show();
        }
    });

</script>

<div class="row first-row">
    <div class="col-sm-12">
        <div class="page-info">
            <div class="dropdown">
                <button class="btn btn-secondary dropdown-toggle" type="button" id="dropdownDB" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    CIFAR-10
                </button>
                <div class="dropdown-menu" aria-labelledby="dropdownDB">
                <a class="dropdown-item" href="/">DASHBOARD</a>
                <a class="dropdown-item" href="mnist">MNIST</a>
                </div>
            </div>
            <div class="leader-title">
                <h2>Public Leaderboard - Computer Vision Competition</h2>
            </div>
        </div>

        <div class="row">
            <div class="col-sm-8 leader-info">
                <p>
                    The CIFAR-10 is a labeled subset of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.
                    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.
                </p>
            </div>
            <div class="col-sm-4 leader-info">
                <button type="button" class="btn btn-success submit-btn" id="submit-btn-cifar10" style="display: none">SUBMIT</button>
            </div>
        </div>
    </div>
</div>

<div class="row cifar10-row leader-table">
    <div class="col-sm-12">
        <h3>CIFAR-10 Scores</h3>
        <table class="table table-cifar10">
            <thead class="thead-dark">
            <tr>
                <th scope="col">#</th>
                <th scope="col">Team Name</th>
                <th scope="col">Score</th>
                <th scope="col">Entries</th>
                <th scope="col">Last Submission <span class="best_text">(Best)</span></th>
            </tr>
            </thead>
            <tbody>
            <!-- LOS RESULTADOS DEBEN SER CARGADOS EN PYTHON Y PROPAGADOS HASTA AQUI CON JAVASCRIPT-->
            <!-- Recordar <tr class="my_submission"> -->
            </tbody>
        </table>
    </div>
</div>

<div class="row submission-guide">
    <div class="col-sm-12">
        <h2>Submission Guide</h2>
        First download the features from <a href="https://drive.google.com/file/d/1EVFqAF4mCG4Oea1p0ILvmBMd-DuQO1TY/view?usp=sharing" target="_blank" class="download-link">here</a>.
        Then follow the instructions below to load the data and make a simple prediction with a pretrained Pytorch model.

        <pre><code class="language-python"># First load/train your Pytorch model
import numpy as np

raw_images = np.load("cifar10_raw_test.npy")
raw_images  = raw_images  / 255 # Normalize range [0, 255] -> [0, 1]

all_preds = np.array(())
# Split data in batcehs -> n is number of batches -> 10000 int 100 batches = batch_size 100
data_batches = np.split(raw_images, 100, axis=0)
for indx, features in enumerate(data_batches):
    with torch.no_grad():
        features = torch.from_numpy(features).float().to(device) # Data to Pytorch tensor
        outputs = net(features) # Model inference
        _, pred = outputs.max(1)  # get the index of the max log-probability
        all_preds = np.append(all_preds, pred.data.cpu().numpy())
# Finally save the predictions -> shape (10000,)
np.save("my_predictions.npy", all_preds)</code></pre>

        Finally, upload your <i>my_predictions.npy</i> generated.

    </div>
</div>

{% endblock %}